{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages and intilize functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import division, unicode_literals, print_function  # for compatibility with Python 2 and 3\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series  # for convenience\n",
    "\n",
    "import pims\n",
    "import trackpy as tp\n",
    "\n",
    "\n",
    "# change the following to %matplotlib notebook for interactive plotting\n",
    "%matplotlib inline\n",
    "\n",
    "# Optionally, tweak styles.\n",
    "mpl.rc('figure',  figsize=(10, 5))\n",
    "mpl.rc('image', cmap='gray')\n",
    "\n",
    "print('ready to go')\n",
    "\n",
    "@pims.pipeline\n",
    "def gray(image):\n",
    "    return image[:, :]  # Take just the green channel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters to define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "## 1) Parameters governing loading and tracking\n",
    "############################################\n",
    "\n",
    "# Do the tracking, linking and filtering. Set these to false if you already performed the tracking and just want to analzye/plot differently\n",
    "perform_tracking = False\n",
    "perform_linking_trajectories = False\n",
    "perform_filtering = False\n",
    "\n",
    "# Directories\n",
    "directory=r'C:\\Users\\Franz\\OneDrive\\_PhD\\My_Papers\\Volvox_Uncertainty_Minimization\\Data\\Figure10_Electroshocked_Phototaxis\\lightSwtiching60sec_random_current3V'\n",
    "save_dir=r'C:\\Users\\Franz\\OneDrive\\_PhD\\My_Papers\\Volvox_Uncertainty_Minimization\\Individual_Graphs\\\\'\n",
    "\n",
    "compress_images=True # True or False if to compress images for better and faster trajectory linking\n",
    "compression_ratio=0.25 # compression ratio (0.1 means images are resized to a tenth of both x and y dimensions)\n",
    "compresion_directory_name_ending='_compressed_0p25'\n",
    "# Note 1: If you have already created the compressed images (because you have run it before), no need to change anything\n",
    "#         it won't do it again and just juse those images. If you want to recompress images, just delete the directory \n",
    "#         that containsthe previously compressed images\n",
    "# Note 2: For all the pixel sizes, midpoint calculations and chamber dimesions, use the original uncompressed image.\n",
    "#         the script will automatically recalculate those based on the ratio. You might have to adjust the filter \n",
    "#         proporties though (see 2) below), as those are not that linearly calculated\n",
    "\n",
    "\n",
    "analyze_subset=True # if this is True, it will only analyze frames starting at frames_to_analyze_start \n",
    "# going to frames_to_analyze_end. Check in the image sequence if there was any moving of the chamber at beginning or end.\n",
    "\n",
    "frames_to_analyze_start=1 # first frame to analyze\n",
    "frames_to_analyze_end=2990 # last frame to analyze\n",
    "\n",
    "minimal_mass_base=1000 # threshold to use for mass (total brightness of an particle= number of pixels * their intensities)\n",
    "# so for example, a 3x3 pixel sized volvox with each of a max intensity of 255 (8bit) would have a mass of 9*255=2295\n",
    "\n",
    "Volvox_pixel_size_estimate=11 # err on the larger side\n",
    "\n",
    "link_distance_pixels=15 # number of pixels to try link trajectories between frames (=distance Volvox move between frames)\n",
    "# need only be larger than 10 if we are undersampling. the larger this distance, the longer the analysis takes. \n",
    "\n",
    "link_memory=5 # number of frames to try link trajectories (=number of frames Volvox could disappear in frames)\n",
    "# need only be larger than 5 for partial illumination conditions like the fixed and random series, but 5 should work too \n",
    "# again,  the higher this value, the longer the analysis takes, and very large values will actually cause an error \n",
    "\n",
    "## 2) Parameters governing filtering trajectories by various characteristics\n",
    "#########################################################################\n",
    "\n",
    "filter_stubs_size=5 # filter out trajctories of things that only appear of x number of frames\n",
    "\n",
    "# for mass and size, look at plot and imagej\n",
    "minimal_mass=1000 # threshold to use for mass (total brightness of an particle= number of pixels * their intensities)\n",
    "\n",
    "filter_by_size=False # True or False to filter by size\n",
    "min_size=2\n",
    "max_size=5\n",
    "\n",
    "filter_by_ecc=False # True or False to filter by eccentricity (non circular shape)\n",
    "max_ecc=0.3\n",
    "\n",
    "filter_by_stds=True # True or False to filter by how much variation you would expect in position in x\n",
    "# This filters out non-moving objects.\n",
    "filter_std=5\n",
    "\n",
    "filter_by_frame_count=False # True or False to filter by how many frames are contained in one trajectory\n",
    "# This filters out Volvox that disappeared, but also removes broken up trajectories (i.e. if the linking failed)\n",
    "filter_frame_count=50\n",
    "\n",
    "## 3) Parameters for counting and plotting\n",
    "#########################################################################\n",
    "\n",
    "midpoint_x=2070  # midpoint in pixel x coordinates of the chamber width in the original, uncompressed image\n",
    "midpoint_y=1120 # midpoint in pixel y coordinates of the chamber height in the original, uncompressed image\n",
    "\n",
    "quartiles=True # if True, is counts volvox in quartile ends of the chamber instead of halfs for more prounced bias counts\n",
    "\n",
    "chamber_width=3000 # chamber width in pixels of the chamber in the original, uncompressed image\n",
    "chamber_height=2000 # chamber height in pixels of the chamber in the original, uncompressed image\n",
    "\n",
    "save_plots=True # Do you want to save the plots? \n",
    "\n",
    "gaussian_smooth=True # True or False for gaussian smoothing of the Volvox count graph over time\n",
    "sigma=15 # frames to average over for gaussian smoothing\n",
    "\n",
    "fps=5 # frames per second of video taking (as in what was your framerate during acquisition)\n",
    "\n",
    "plot_left_right_bias=False # True or False to plot the left-right bias counts\n",
    "plot_top_bottom_bias=True  # True or False to plot the top-bottom bias counts\n",
    "\n",
    "# Labels for the individual stimulation condtions (light pattern, anode/cathode side etc.)\n",
    "label_left=\"Right half\"\n",
    "label_right=\"Left half\"\n",
    "label_top=\"Top Light\"\n",
    "label_bottom=\"Bottom Light\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compress Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "\n",
    "base_dir=str(Path(directory).parents[0]) \n",
    "sub_folder_name=os.path.basename(directory)  \n",
    "\n",
    "if compress_images and perform_tracking:\n",
    "    directory_new=directory+compresion_directory_name_ending\n",
    "    if os.path.exists(directory_new)==False:\n",
    "        os.mkdir(directory_new)\n",
    "        for file_name in os.listdir(directory):\n",
    "            #print(\"Processing %s\" % file_name)\n",
    "            img = Image.open(os.path.join(directory, file_name))\n",
    "            x,y = img.size\n",
    "            output = img.resize((int(x * compression_ratio), int(y* compression_ratio)), Image.ANTIALIAS)\n",
    "\n",
    "            output_file_name = os.path.join(directory_new, file_name)\n",
    "            output.save(output_file_name, \"tiff\", quality = 95)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if not compress_images:\n",
    "    directory_new=directory\n",
    "else:\n",
    "    directory_new=directory+compresion_directory_name_ending\n",
    "\n",
    "base_dir=str(Path(directory_new).parents[0]) \n",
    "sub_folder_name=os.path.basename(directory_new)\n",
    "    \n",
    "if perform_tracking:\n",
    "    print(directory_new)\n",
    "    frames = gray(pims.open(directory_new+'/*.tiff'))\n",
    "    plt.imshow(frames[frames_to_analyze_start])\n",
    "    f = tp.locate(frames[frames_to_analyze_start],  int(Volvox_pixel_size_estimate), invert=False)\n",
    "    f.head() \n",
    "    tp.annotate(f, frames[frames_to_analyze_start]);\n",
    "    if analyze_subset:\n",
    "        f = tp.batch(frames[frames_to_analyze_start:frames_to_analyze_end],  int(Volvox_pixel_size_estimate), minmass=minimal_mass_base, invert=False);\n",
    "    else:\n",
    "        f = tp.batch(frames, int(Volvox_pixel_size_estimate), minmass=minimal_mass, invert=False);\n",
    "\n",
    "    base_dir=str(Path(directory_new).parents[0]) \n",
    "    sub_folder_name=os.path.basename(directory_new)\n",
    "\n",
    "    f.to_csv(base_dir+'\\\\'+sub_folder_name+'_frames.csv')\n",
    "    print(f.columns)\n",
    "elif perform_linking_trajectories:\n",
    "    f=pd.read_csv(base_dir+'\\\\'+sub_folder_name+'_frames.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Link trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if perform_linking_trajectories:\n",
    "    t = tp.link_df(f, link_distance_pixels , memory=link_memory)\n",
    "\n",
    "    t.to_csv(base_dir+'\\\\'+sub_folder_name+'_trajectories_raw.csv')\n",
    "elif perform_filtering:\n",
    "    t=pd.read_csv(base_dir+'\\\\'+sub_folder_name+'_trajectories_raw.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter particle trajectory by size, mass, eccentricity, stds, and frame count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "if perform_filtering:\n",
    "    t.head()\n",
    "    t1 = tp.filter_stubs(t, filter_stubs_size)\n",
    "    plt.figure()\n",
    "\n",
    "    tp.mass_size(t1.groupby('particle').mean()); # convenience function -- just plots size vs. mass\n",
    "\n",
    "    if filter_by_size:\n",
    "        if filter_by_ecc:\n",
    "            t2 = t1[((t1['mass'] > minimal_mass) & (t1['size'] > min_size)& (t1['size'] < max_size) & (t1['ecc'] < max_ecc))]\n",
    "        else:    \n",
    "            t2 = t1[((t1['mass'] > minimal_mass) & (t1['size'] > min_size)& (t1['size'] < max_size))]\n",
    "    else:\n",
    "        if filter_by_ecc:\n",
    "            t2 = t1[((t1['mass'] > minimal_mass) & (t1['ecc'] < max_ecc))]\n",
    "        else:    \n",
    "            t2 = t1[((t1['mass'] > minimal_mass))]\n",
    "    print('particles filter by size/mass/ecc =', len((list(set(t1.particle))))-len((list(set(t2.particle)))), 'out of', len((list(set(t1.particle)))))\n",
    "\n",
    "    if filter_by_stds:\n",
    "\n",
    "        t2p5=t2.copy()\n",
    "        std=t2.groupby(['particle']).std()\n",
    "        std.reset_index(level=0, inplace=True)\n",
    "\n",
    "        list_set = set(t2.particle)\n",
    "        unique_list = (list(list_set))\n",
    "        unique_list.sort()\n",
    "        for i in unique_list:\n",
    "            std_x=float(std.loc[std.particle==i,'x'])\n",
    "            if std_x<filter_std:\n",
    "                t2p5=t2p5[t2p5['particle'] != i]\n",
    "            elif math.isnan(std_x):\n",
    "                t2p5=t2p5[t2p5['particle'] != i]\n",
    "\n",
    "        len((list(set(t2p5.particle))))\n",
    "        print('particles filter by stds =', len((list(set(t2.particle))))-len((list(set(t2p5.particle)))), 'out of', len((list(set(t2.particle)))))\n",
    "        t2=t2p5.copy()\n",
    "\n",
    "\n",
    "\n",
    "    t3=t2.copy()\n",
    "\n",
    "    if filter_by_frame_count:\n",
    "        list_set = set(t3.frame)\n",
    "        unique_list = (list(list_set))\n",
    "        unique_list.sort()\n",
    "        for i in unique_list:\n",
    "            t3i=t3[t3.frame==i]\n",
    "            if t3i.frame.count()<filter_frame_count:\n",
    "                t3=t3[t3['frame'] != i]\n",
    "\n",
    "        print('particles filter by frame count =', len((list(set(t2.particle))))-len((list(set(t3.particle)))), 'out of', len((list(set(t2.particle)))))\n",
    "\n",
    "\n",
    "    plt.figure()\n",
    "    tp.annotate(t3[t3['frame'] == frames_to_analyze_start], frames[frames_to_analyze_start]);\n",
    "    plt.figure()\n",
    "    tp.plot_traj(t3);\n",
    "\n",
    "    t4=t3.copy()\n",
    "\n",
    "    t4.to_csv(base_dir+'\\\\'+sub_folder_name+'_trajectories_filtered.csv')\n",
    "    \n",
    "else:\n",
    "    t4=pd.read_csv(base_dir+'\\\\'+sub_folder_name+'_trajectories_filtered.csv')\n",
    "\n",
    "list_set = set(t4.frame)\n",
    "unique_list = (list(list_set))\n",
    "unique_list.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count particles in each frame in each half of the chamber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=np.zeros(len(unique_list))\n",
    "r=np.zeros(len(unique_list))\n",
    "\n",
    "t=np.zeros(len(unique_list))\n",
    "b=np.zeros(len(unique_list))\n",
    "\n",
    "if not compress_images:\n",
    "    compression_ratio=1\n",
    "if quartiles:\n",
    "    x1=int(midpoint_x*compression_ratio)-int(chamber_width*compression_ratio/4)\n",
    "    x2=int(midpoint_x*compression_ratio)+int(chamber_width*compression_ratio/4)\n",
    "    y1=int(midpoint_y*compression_ratio)-int(chamber_height*compression_ratio/4)\n",
    "    y2=int(midpoint_y*compression_ratio)+int(chamber_height*compression_ratio/4)  \n",
    "else:\n",
    "    x1=int(midpoint_x*compression_ratio)\n",
    "    x2=int(midpoint_x*compression_ratio)-1\n",
    "    y1=int(midpoint_y*compression_ratio)\n",
    "    y2=int(midpoint_y*compression_ratio)-1\n",
    "\n",
    "\n",
    "# print(unique_list)\n",
    "ii=0\n",
    "for i in unique_list:\n",
    "    t5=t4.loc[t4.frame==i]\n",
    "    \n",
    "    t_left=t5.loc[t5.x<x1]\n",
    "    t_right=t5.loc[t5.x>x2]    \n",
    "    \n",
    "    t_top=t5.loc[t5.y<y1]\n",
    "    t_bottom=t5.loc[t5.y>y2]\n",
    "\n",
    "    l[ii]=t_left.shape[0]\n",
    "    r[ii]=t_right.shape[0]\n",
    "    \n",
    "    \n",
    "    t[ii]=t_top.shape[0]\n",
    "    b[ii]=t_bottom.shape[0]\n",
    "\n",
    "    ii=ii+1\n",
    "    \n",
    "\n",
    "print('mean # left : ',l.mean())\n",
    "print('mean # right : ',r.mean())\n",
    "\n",
    "print('mean # top : ',t.mean())\n",
    "print('mean # bottom : ',b.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smooth and plot trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "\n",
    "if gaussian_smooth:\n",
    "    l=sp.ndimage.gaussian_filter1d(l,sigma)\n",
    "    r=sp.ndimage.gaussian_filter1d(r,sigma)\n",
    "    t=sp.ndimage.gaussian_filter1d(t,sigma)\n",
    "    b=sp.ndimage.gaussian_filter1d(b,sigma)\n",
    "\n",
    "unique_list_time=np.array(unique_list)/fps\n",
    "\n",
    "fig=plt.figure(figsize=(7,4))\n",
    "\n",
    "if plot_left_right_bias:\n",
    "    ax=plt.plot(unique_list_time, l, \"-b\", label=label_left)\n",
    "    ax=plt.plot(unique_list_time, r, \"--b\", label=label_right)\n",
    "    \n",
    "if plot_top_bottom_bias:\n",
    "    ax=plt.plot(unique_list_time, t, \"-r\", label=label_top)\n",
    "    ax=plt.plot(unique_list_time, b, \"--r\", label=label_bottom)\n",
    "ax=plt.legend(bbox_to_anchor=(1,1), loc=\"upper left\")\n",
    "ax=plt.xlabel('time (in s)')\n",
    "ax=plt.ylabel('number of Volvox')\n",
    "plt.show()\n",
    "\n",
    "save_path=base_dir+'\\\\'+sub_folder_name+'_Volvox_counts_line_graph.png'\n",
    "\n",
    "if save_plots:\n",
    "    fig.savefig(save_path, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Half only - Counting and Ploting Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=np.zeros(len(unique_list))\n",
    "r=np.zeros(len(unique_list))\n",
    "\n",
    "t=np.zeros(len(unique_list))\n",
    "b=np.zeros(len(unique_list))\n",
    "\n",
    "if not compress_images:\n",
    "    compression_ratio=1\n",
    "\n",
    "x1=int(midpoint_x*compression_ratio)\n",
    "x2=int(midpoint_x*compression_ratio)-1\n",
    "y1=int(midpoint_y*compression_ratio)\n",
    "y2=int(midpoint_y*compression_ratio)-1\n",
    "\n",
    "\n",
    "# print(unique_list)\n",
    "ii=0\n",
    "for i in unique_list:\n",
    "    t5=t4.loc[t4.frame==i]\n",
    "    \n",
    "    t_left=t5.loc[t5.x<x1]\n",
    "    t_right=t5.loc[t5.x>x2]    \n",
    "    \n",
    "    t_top=t5.loc[t5.y<y1]\n",
    "    t_bottom=t5.loc[t5.y>y2]\n",
    "\n",
    "    l[ii]=t_left.shape[0]\n",
    "    r[ii]=t_right.shape[0]\n",
    "    \n",
    "    \n",
    "    t[ii]=t_top.shape[0]\n",
    "    b[ii]=t_bottom.shape[0]\n",
    "\n",
    "    ii=ii+1\n",
    "    \n",
    "\n",
    "print('mean # left : ',l.mean())\n",
    "print('mean # right : ',r.mean())\n",
    "\n",
    "print('mean # top : ',t.mean())\n",
    "print('mean # bottom : ',b.mean())\n",
    "\n",
    "import scipy as sp\n",
    "\n",
    "if gaussian_smooth:\n",
    "    l=sp.ndimage.gaussian_filter1d(l,sigma)\n",
    "    r=sp.ndimage.gaussian_filter1d(r,sigma)\n",
    "    t=sp.ndimage.gaussian_filter1d(t,sigma)\n",
    "    b=sp.ndimage.gaussian_filter1d(b,sigma)\n",
    "\n",
    "unique_list_time=np.array(unique_list)/fps\n",
    "\n",
    "fig=plt.figure(figsize=(7,4))\n",
    "\n",
    "if plot_left_right_bias:\n",
    "    ax=plt.plot(unique_list_time, l, \"-b\", label=label_left)\n",
    "    ax=plt.plot(unique_list_time, r, \"--b\", label=label_right)\n",
    "    \n",
    "if plot_top_bottom_bias:\n",
    "    ax=plt.plot(unique_list_time, t, \"-r\", label=label_top)\n",
    "    ax=plt.plot(unique_list_time, b, \"--r\", label=label_bottom)\n",
    "ax=plt.legend(bbox_to_anchor=(1,1), loc=\"upper left\")\n",
    "ax=plt.xlabel('time (in s)')\n",
    "ax=plt.ylabel('number of Volvox')\n",
    "plt.show()\n",
    "\n",
    "save_path=base_dir+'\\\\'+sub_folder_name+'_Volvox_counts_line_graph_halfs.png'\n",
    "\n",
    "if save_plots:\n",
    "    fig.savefig(save_path, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quartile only - Counting and Ploting Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=np.zeros(len(unique_list))\n",
    "r=np.zeros(len(unique_list))\n",
    "\n",
    "t=np.zeros(len(unique_list))\n",
    "b=np.zeros(len(unique_list))\n",
    "\n",
    "if not compress_images:\n",
    "    compression_ratio=1\n",
    "\n",
    "x1=int(midpoint_x*compression_ratio)-int(chamber_width*compression_ratio/4)\n",
    "x2=int(midpoint_x*compression_ratio)+int(chamber_width*compression_ratio/4)\n",
    "y1=int(midpoint_y*compression_ratio)-int(chamber_height*compression_ratio/4)\n",
    "y2=int(midpoint_y*compression_ratio)+int(chamber_height*compression_ratio/4)  \n",
    "\n",
    "\n",
    "# print(unique_list)\n",
    "ii=0\n",
    "for i in unique_list:\n",
    "    t5=t4.loc[t4.frame==i]\n",
    "    \n",
    "    t_left=t5.loc[t5.x<x1]\n",
    "    t_right=t5.loc[t5.x>x2]    \n",
    "    \n",
    "    t_top=t5.loc[t5.y<y1]\n",
    "    t_bottom=t5.loc[t5.y>y2]\n",
    "\n",
    "    l[ii]=t_left.shape[0]\n",
    "    r[ii]=t_right.shape[0]\n",
    "    \n",
    "    \n",
    "    t[ii]=t_top.shape[0]\n",
    "    b[ii]=t_bottom.shape[0]\n",
    "\n",
    "    ii=ii+1\n",
    "    \n",
    "\n",
    "print('mean # left : ',l.mean())\n",
    "print('mean # right : ',r.mean())\n",
    "\n",
    "print('mean # top : ',t.mean())\n",
    "print('mean # bottom : ',b.mean())\n",
    "\n",
    "import scipy as sp\n",
    "\n",
    "if gaussian_smooth:\n",
    "    l=sp.ndimage.gaussian_filter1d(l,sigma)\n",
    "    r=sp.ndimage.gaussian_filter1d(r,sigma)\n",
    "    t=sp.ndimage.gaussian_filter1d(t,sigma)\n",
    "    b=sp.ndimage.gaussian_filter1d(b,sigma)\n",
    "\n",
    "unique_list_time=np.array(unique_list)/fps\n",
    "\n",
    "fig=plt.figure(figsize=(7,4))\n",
    "\n",
    "if plot_left_right_bias:\n",
    "    ax=plt.plot(unique_list_time, l, \"-b\", label=label_left)\n",
    "    ax=plt.plot(unique_list_time, r, \"--b\", label=label_right)\n",
    "    \n",
    "if plot_top_bottom_bias:\n",
    "    ax=plt.plot(unique_list_time, t, \"-b\", label=label_top)\n",
    "    ax=plt.plot(unique_list_time, b, \"-r\", label=label_bottom)\n",
    "ax=plt.legend(bbox_to_anchor=(1,1), loc=\"upper left\")\n",
    "ax=plt.xlabel('time (in s)')\n",
    "ax=plt.ylabel('number of Volvox')\n",
    "plt.show()\n",
    "\n",
    "save_path=base_dir+'\\\\'+sub_folder_name+'_Volvox_counts_line_graph_quartiles2.png'\n",
    "if save_plots:\n",
    "    fig.savefig(save_path, bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
